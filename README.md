Credit to https://github.com/Heewon-Hailey/multi-armed-bandits-for-recommendation-systems for the initial implementations of bandits, which we used and modified
